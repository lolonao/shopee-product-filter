import os
import sys
import logging
from typing import List, Optional, Dict, Any, Annotated
from datetime import datetime, timezone
import tempfile
from contextlib import asynccontextmanager

# FastAPI ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from fastapi import FastAPI, Depends, HTTPException, status, UploadFile, File, Query
from fastapi.responses import HTMLResponse
# SQLModel ã¨ SQLAlchemy ã® select
from sqlmodel import Field, Session, SQLModel, create_engine, select
from sqlalchemy.sql.expression import and_
from pydantic import BaseModel

# parse_product_list.py ã‚’åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from ..core.parse_product_list import parse_shopee_shop_products_from_file_final

# BeautifulSoup ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from bs4 import BeautifulSoup

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(levelname)s:%(name)s:%(message)s')
logger = logging.getLogger(__name__)

# --- å•†å“ãƒªã‚¹ãƒˆæƒ…å ±å°‚ç”¨ã®DBè¨­å®š ---
DB_FILE_PRODUCT_LIST = "shopee_product_list_data.db"
DATABASE_URL_PRODUCT_LIST = f"sqlite:///{DB_FILE_PRODUCT_LIST}"

logger.info(f"å•†å“ãƒªã‚¹ãƒˆæƒ…å ±APIã¯ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ« '{DB_FILE_PRODUCT_LIST}' ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")

engine_product_list = create_engine(DATABASE_URL_PRODUCT_LIST, echo=False)

# --- SQLModelã®å•†å“ãƒªã‚¹ãƒˆæƒ…å ±ãƒ¢ãƒ‡ãƒ«å®šç¾© (å¤‰æ›´ãªã—) ---
class ProductBasicItem(SQLModel, table=True):
    id: Optional[int] = Field(default=None, primary_key=True, index=True)
    product_url: str = Field(unique=True, index=True, max_length=2048)
    product_name: Optional[str] = Field(default=None, max_length=512)
    price: Optional[float] = None
    currency: Optional[str] = Field(default=None, max_length=10)
    image_url: Optional[str] = Field(default=None, max_length=2048)
    location: Optional[str] = Field(default=None, max_length=255)
    sold: Optional[int] = Field(default=0)
    shop_type: Optional[str] = Field(default=None, max_length=50)
    list_type: Optional[str] = Field(default=None, max_length=50)
    sourcing_status: Optional[str] = Field(default=None, index=True, max_length=50)
    sourcing_notes: Optional[str] = Field(default=None)
    status_updated_at: Optional[datetime] = Field(default=None)
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc), nullable=False)
    updated_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc), nullable=False)

# --- ã‚½ãƒ¼ã‚·ãƒ³ã‚°æƒ…å ±æ›´æ–°ç”¨ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ãƒ¢ãƒ‡ãƒ« (å¤‰æ›´ãªã—) ---
class SourcingInfoUpdate(BaseModel):
    sourcing_status: Optional[str] = None
    sourcing_notes: Optional[str] = None

# --- FastAPIã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ã‚¤ãƒ™ãƒ³ãƒˆç®¡ç† (å¤‰æ›´ãªã—) ---
@asynccontextmanager
async def lifespan(app: FastAPI):
    logger.info(f"å•†å“ãƒªã‚¹ãƒˆæƒ…å ±APIèµ·å‹•ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é–‹å§‹ (lifespan)ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«: '{DB_FILE_PRODUCT_LIST}'")
    try:
        SQLModel.metadata.create_all(engine_product_list)
        actual_table_name = "productbasicitem"
        logger.info(f"å•†å“ãƒªã‚¹ãƒˆæƒ…å ±ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ '{DB_FILE_PRODUCT_LIST}' ã®ãƒ†ãƒ¼ãƒ–ãƒ« '{actual_table_name}' ã‚’ç¢ºèª/ä½œæˆã—ã¾ã—ãŸã€‚")
    except Exception as e:
        logger.critical(f"å•†å“ãƒªã‚¹ãƒˆæƒ…å ±ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ '{DB_FILE_PRODUCT_LIST}' ã®èµ·å‹•ã‚¨ãƒ©ãƒ¼ (lifespan): {e}", exc_info=True)
    yield
    logger.info("å•†å“ãƒªã‚¹ãƒˆæƒ…å ±APIã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³å®Œäº† (lifespan)ã€‚")

# FastAPIã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ç”Ÿæˆ
product_list_app = FastAPI(
    title="ğŸ›ï¸ Shopee å•†å“ãƒªã‚¹ãƒˆæƒ…å ± API (ã‚½ãƒ¼ã‚·ãƒ³ã‚°æ©Ÿèƒ½ä»˜ã)",
    description="å•†å“ä¸€è¦§HTMLã‹ã‚‰æŠ½å‡ºã—ãŸåŸºæœ¬æƒ…å ±ã‚’ç®¡ç†ãƒ»æ¤œç´¢ã—ã€ã‚½ãƒ¼ã‚·ãƒ³ã‚°çŠ¶æ³ã‚‚è¨˜éŒ²ã§ãã‚‹APIã ãœï¼",
    version="1.1.7", # å¼•æ•°ã®é †ç•ª ä¿®æ­£ãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼
    lifespan=lifespan
)

# --- DBã‚»ãƒƒã‚·ãƒ§ãƒ³ã®å®šç¾© (å¤‰æ›´ãªã—) ---
def get_product_list_session():
    with Session(engine_product_list) as session:
        yield session
ProductListSession = Annotated[Session, Depends(get_product_list_session)]


# --- API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ---
@product_list_app.get("/", response_class=HTMLResponse, summary="å•†å“ãƒªã‚¹ãƒˆAPIã®ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸")
async def read_product_list_root():
    # (å†…å®¹ã¯å¤‰æ›´ãªã—)
    return f"""
    <html><head><title>Shopee å•†å“ãƒªã‚¹ãƒˆæƒ…å ± API (ã‚½ãƒ¼ã‚·ãƒ³ã‚°æ©Ÿèƒ½ä»˜ã)</title></head>
    <body><h1>ğŸ›ï¸ Shopee å•†å“ãƒªã‚¹ãƒˆæƒ…å ± API ã¸ã‚ˆã†ã“ãï¼</h1>
    <p>ã“ã®APIã¯å•†å“ãƒªã‚¹ãƒˆã®åŸºæœ¬æƒ…å ±ã¨ã‚½ãƒ¼ã‚·ãƒ³ã‚°çŠ¶æ³ã‚’ç®¡ç†ã—ã¾ã™ã€‚Streamlitã‚¢ãƒ—ãƒªã‹ã‚‰ã©ã†ãã€‚</p>
    <ul><li><a href="/docs">APIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ (Swagger UI)</a></li><li><a href="/redoc">APIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ (ReDoc)</a></li><li><a href="/basic-products/">DBå†…å•†å“ãƒªã‚¹ãƒˆæƒ…å ±å–å¾—</a></li></ul>
    </body></html>"""

@product_list_app.get("/basic-products/", response_model=List[ProductBasicItem], summary="å•†å“ãƒªã‚¹ãƒˆæƒ…å ±ã‚’å–å¾—ãƒ»æ¤œç´¢")
def get_basic_products_with_filters(
    # â˜…â˜…â˜… session ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’æŒã¤å¼•æ•°ã®å‰ã«æŒã£ã¦ãã‚‹ â˜…â˜…â˜…
    session: ProductListSession,
    offset: int = 0,
    limit: int = Query(default=100, le=200),
    min_price_sgd: Optional[float] = Query(default=None),
    max_price_sgd: Optional[float] = Query(default=None),
    min_sold: Optional[int] = Query(default=None),
    max_sold: Optional[int] = Query(default=None),
    shop_type: Optional[str] = Query(default=None),
    list_type: Optional[str] = Query(default=None),
    sourcing_status: Optional[str] = Query(default=None),
    start_date_created: Optional[datetime] = Query(default=None),
    end_date_created: Optional[datetime] = Query(default=None),
):
    conditions = []
    if min_price_sgd is not None: conditions.append(ProductBasicItem.price >= min_price_sgd)  # type: ignore
    if max_price_sgd is not None: conditions.append(ProductBasicItem.price <= max_price_sgd)  # type: ignore
    if min_sold is not None: conditions.append(ProductBasicItem.sold >= min_sold)      # type: ignore
    if max_sold is not None: conditions.append(ProductBasicItem.sold <= max_sold)      # type: ignore
    if shop_type: conditions.append(ProductBasicItem.shop_type == shop_type)  # type: ignore
    if list_type: conditions.append(ProductBasicItem.list_type == list_type)  # type: ignore
    if sourcing_status: conditions.append(ProductBasicItem.sourcing_status == sourcing_status) # type: ignore
    if start_date_created: conditions.append(ProductBasicItem.created_at >= start_date_created) # type: ignore
    if end_date_created: conditions.append(ProductBasicItem.created_at <= end_date_created) # type: ignore
    
    statement = select(ProductBasicItem)
    if conditions:
        statement = statement.where(and_(*conditions))
        
    statement = statement.offset(offset).limit(limit).order_by(ProductBasicItem.id)
    products = session.exec(statement).all()
    return products if products else []


@product_list_app.get("/basic-products/{item_id}", response_model=ProductBasicItem, summary="ç‰¹å®šã®å•†å“ãƒªã‚¹ãƒˆæƒ…å ±ã‚’IDã§å–å¾—")
def get_basic_product_by_id(
    # â˜…â˜…â˜… session ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’æŒã¤å¼•æ•°ã®å‰ã«æŒã£ã¦ãã‚‹ (ã“ã®é–¢æ•°ã¯ item_id ãŒå¿…é ˆãªã®ã§å…ƒã€…OKã ã£ãŸ) â˜…â˜…â˜…
    item_id: int, 
    session: ProductListSession
):
    product = session.get(ProductBasicItem, item_id)
    if not product:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="å•†å“ãƒªã‚¹ãƒˆã‚¢ã‚¤ãƒ†ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    return product

@product_list_app.put("/basic-products/{item_id}/sourcing-info", response_model=ProductBasicItem, summary="ç‰¹å®šå•†å“ã®ã‚½ãƒ¼ã‚·ãƒ³ã‚°æƒ…å ±ã‚’æ›´æ–°")
def update_sourcing_info(
    # â˜…â˜…â˜… session ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’æŒã¤å¼•æ•°ã®å‰ã«æŒã£ã¦ãã‚‹ (item_id ã¨ sourcing_info ãŒå¿…é ˆãªã®ã§å…ƒã€…OKã ã£ãŸ) â˜…â˜…â˜…
    item_id: int,
    sourcing_info: SourcingInfoUpdate,
    session: ProductListSession
):
    db_item = session.get(ProductBasicItem, item_id)
    if not db_item:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="å•†å“ãƒªã‚¹ãƒˆã‚¢ã‚¤ãƒ†ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    update_data = sourcing_info.model_dump(exclude_unset=True)
    changed = False
    for field_name, value in update_data.items():
        if hasattr(db_item, field_name) and getattr(db_item, field_name) != value:
            setattr(db_item, field_name, value)
            changed = True
    if changed:
        current_time = datetime.now(timezone.utc)
        db_item.status_updated_at = current_time
        db_item.updated_at = current_time
        session.add(db_item)
        session.commit()
        session.refresh(db_item)
        logger.info(f"å•†å“ID {item_id} ã®ã‚½ãƒ¼ã‚·ãƒ³ã‚°æƒ…å ±ã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚")
    else:
        logger.info(f"å•†å“ID {item_id} ã®ã‚½ãƒ¼ã‚·ãƒ³ã‚°æƒ…å ±ã«å¤‰æ›´ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    return db_item

@product_list_app.post("/upload-product-list-html/", summary="å•†å“ãƒªã‚¹ãƒˆHTMLã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦DBã«ä¿å­˜/æ›´æ–°")
async def upload_product_list_html_and_save(
    # â˜…â˜…â˜… session ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’æŒã¤å¼•æ•°ã®å‰ã«æŒã£ã¦ãã‚‹ â˜…â˜…â˜…
    session: ProductListSession, 
    html_files: List[UploadFile] = File(...)
):
    # (ä»¥é™ã®ãƒ­ã‚¸ãƒƒã‚¯ã¯å¤‰æ›´ãªã—)
    processed_results = []
    for html_file in html_files:
        file_name = html_file.filename
        logger.info(f"å•†å“ãƒªã‚¹ãƒˆHTMLãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†é–‹å§‹: {file_name}")
        temp_file_path = None
        try:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".html", mode="w+b") as tmp:
                content = await html_file.read()
                tmp.write(content)
                temp_file_path = tmp.name
            
            parsed_items: Optional[List[Dict[str, Any]]] = parse_shopee_shop_products_from_file_final(temp_file_path)

            if parsed_items is None:
                logger.warning(f"ãƒ•ã‚¡ã‚¤ãƒ« '{file_name}' ã‹ã‚‰å•†å“ãƒªã‚¹ãƒˆã®ã‚³ãƒ³ãƒ†ãƒŠãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                processed_results.append({"file_name": file_name, "status": "skipped", "message": "å•†å“ãƒªã‚¹ãƒˆã®ã‚³ãƒ³ãƒ†ãƒŠãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"})
                continue
            if not parsed_items:
                logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ« '{file_name}' ã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸå•†å“ã‚¢ã‚¤ãƒ†ãƒ ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                processed_results.append({"file_name": file_name, "status": "success", "message": "æŠ½å‡ºã‚¢ã‚¤ãƒ†ãƒ ãªã—", "items_processed": 0})
                continue

            items_processed_count = 0
            soup_for_list_type = BeautifulSoup(content.decode('utf-8', errors='ignore'), 'lxml')
            detected_list_type = "ä¸æ˜"
            if soup_for_list_type.select('div.shop-search-result-view > div.row > div.shop-search-result-view__item'):
                detected_list_type = "ã‚·ãƒ§ãƒƒãƒ—"
            elif soup_for_list_type.select('li.col-xs-2-4.shopee-search-item-result__item'):
                detected_list_type = "æ¤œç´¢/ã‚«ãƒ†ã‚´ãƒªãƒ¼"
            elif soup_for_list_type.select('li[data-sqe="item"]'):
                detected_list_type = "æ±ç”¨"
            logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ« '{file_name}' ã®æ¤œå‡ºãƒªã‚¹ãƒˆã‚¿ã‚¤ãƒ—: {detected_list_type}")

            for item_data in parsed_items:
                product_url = item_data.get("product_url")
                if not product_url:
                    logger.warning(f"ã‚¢ã‚¤ãƒ†ãƒ ã«product_urlãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿: {item_data}")
                    continue
                
                existing_item = session.exec(
                    select(ProductBasicItem).where(ProductBasicItem.product_url == product_url)
                ).first()
                current_time = datetime.now(timezone.utc)
                valid_model_keys = ProductBasicItem.model_fields.keys()

                if existing_item:
                    logger.info(f"å•†å“URL '{product_url}' ã¯æ—¢å­˜ã®ãŸã‚ã€æ›´æ–°ã—ã¾ã™ã€‚ (ãƒ•ã‚¡ã‚¤ãƒ«: {file_name})")
                    update_data = { k: v for k, v in item_data.items() if k in valid_model_keys and k not in ["created_at", "id", "sourcing_status", "sourcing_notes", "status_updated_at"]}
                    for key, value in update_data.items():
                        setattr(existing_item, key, value)
                    existing_item.list_type = detected_list_type
                    existing_item.updated_at = current_time
                    session.add(existing_item)
                else:
                    logger.info(f"å•†å“URL '{product_url}' ã¯æ–°è¦ã®ãŸã‚ã€è¿½åŠ ã—ã¾ã™ã€‚ (ãƒ•ã‚¡ã‚¤ãƒ«: {file_name})")
                    new_item_data_with_list_type = {**item_data, "list_type": detected_list_type}
                    filtered_new_item_data = { k: v for k, v in new_item_data_with_list_type.items() if k in valid_model_keys and k != "id"}
                    new_item = ProductBasicItem(**filtered_new_item_data)
                    session.add(new_item)
                items_processed_count += 1
            
            session.commit()
            processed_results.append({"file_name": file_name, "status": "success", "message": f"{items_processed_count} ã‚¢ã‚¤ãƒ†ãƒ å‡¦ç†å®Œäº†", "items_processed": items_processed_count})
            logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ« '{file_name}' ã®DBä¿å­˜/æ›´æ–°ãŒå®Œäº†ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚¢ã‚¤ãƒ†ãƒ æ•°: {items_processed_count}")

        except HTTPException:
            session.rollback()
            processed_results.append({"file_name": file_name, "status": "error", "message": "å‡¦ç†ä¸­ã«HTTPã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"})
            raise
        except Exception as e:
            session.rollback()
            logger.error(f"å•†å“ãƒªã‚¹ãƒˆHTML '{file_name}' ã®å‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", exc_info=True)
            processed_results.append({"file_name": file_name, "status": "error", "message": f"äºˆæœŸã›ã¬ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼: {e}"})
        finally:
            if temp_file_path and os.path.exists(temp_file_path):
                try: os.remove(temp_file_path)
                except Exception as e_remove: logger.error(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ã«å¤±æ•—: {temp_file_path}, ã‚¨ãƒ©ãƒ¼: {e_remove}")
                    
    return processed_results

